{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab exercise, we will perform some POS Tagging and\n",
    "Lemmatization.\n",
    "1. Import the necessary libraries.\n",
    "\n",
    "2. Given a text from a file : LabE5.txt\n",
    "a. For each word in the sentence, tag / mark the corresponding POS using any POS tagger\n",
    "b. Reduce each words to lemma based on the POS tagger\n",
    "\n",
    "3. For same text in text file\n",
    "a. Compare the tags generated spaCy and NLTK.\n",
    "b. Use Penn Tree Bank Tagset\n",
    "4. Give few product reviews from the file: LabE_5.txt\n",
    "a. Extract product descriptors of the concerned product.\n",
    "b. Here use spaCy : for getting descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\loviy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\loviy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\loviy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Import the necessary libraries\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': 'Great', 'pos_tag': 'NN'}\n",
      "{'word': 'buy,', 'pos_tag': 'NN'}\n",
      "{'word': 'always', 'pos_tag': 'RB'}\n",
      "{'word': 'go', 'pos_tag': 'VB'}\n",
      "{'word': 'with', 'pos_tag': 'IN'}\n",
      "{'word': 'white', 'pos_tag': 'JJ'}\n",
      "{'word': 'dark', 'pos_tag': 'NN'}\n",
      "{'word': 'colors', 'pos_tag': 'NNS'}\n",
      "{'word': 'melt', 'pos_tag': 'NN'}\n",
      "{'word': 'on', 'pos_tag': 'IN'}\n"
     ]
    }
   ],
   "source": [
    "# 2. Given a text from a file : LabE5.txt\n",
    "# 2.a) For each word in the sentence, tag / mark the corresponding POS using any POS tagger\n",
    "lab5_text_raw = open(\"LabE_5.txt\", \"r\").read()\n",
    "\n",
    "lab5_text_words = lab5_text_raw.split()\n",
    "\n",
    "pos_tag_map = []\n",
    "\n",
    "for word in lab5_text_words:\n",
    "    pos_tag_map.append({\n",
    "        \"word\": word,\n",
    "        \"pos_tag\": pos_tag([word])[0][1]\n",
    "    })\n",
    "\n",
    "for word in pos_tag_map[:10]:\n",
    "    print(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': 'Great', 'pos_tag': 'NN', 'lemma': 'Great'}\n",
      "{'word': 'buy,', 'pos_tag': 'NN', 'lemma': 'buy,'}\n",
      "{'word': 'always', 'pos_tag': 'RB', 'lemma': 'always'}\n",
      "{'word': 'go', 'pos_tag': 'VB', 'lemma': 'go'}\n",
      "{'word': 'with', 'pos_tag': 'IN', 'lemma': 'with'}\n",
      "{'word': 'white', 'pos_tag': 'JJ', 'lemma': 'white'}\n",
      "{'word': 'dark', 'pos_tag': 'NN', 'lemma': 'dark'}\n",
      "{'word': 'colors', 'pos_tag': 'NNS', 'lemma': 'color'}\n",
      "{'word': 'melt', 'pos_tag': 'NN', 'lemma': 'melt'}\n",
      "{'word': 'on', 'pos_tag': 'IN', 'lemma': 'on'}\n"
     ]
    }
   ],
   "source": [
    "# 2.b) Reduce each words to lemma based on the POS tagger\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for word in pos_tag_map:\n",
    "    word[\"lemma\"] = lemmatizer.lemmatize(word[\"word\"])\n",
    "\n",
    "for word in pos_tag_map[:10]:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.5.0-cp39-cp39-win_amd64.whl (12.2 MB)\n",
      "     --------------------------------------- 12.2/12.2 MB 15.2 MB/s eta 0:00:00\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy) (1.21.5)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "     ------------------------------------- 181.6/181.6 kB 10.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy) (63.4.1)\n",
      "Collecting typer<0.8.0,>=0.3.0\n",
      "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.8-cp39-cp39-win_amd64.whl (96 kB)\n",
      "     ---------------------------------------- 96.8/96.8 kB 5.4 MB/s eta 0:00:00\n",
      "Collecting thinc<8.2.0,>=8.1.0\n",
      "  Downloading thinc-8.1.7-cp39-cp39-win_amd64.whl (1.3 MB)\n",
      "     ---------------------------------------- 1.3/1.3 MB 20.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Collecting pathy>=0.10.0\n",
      "  Downloading pathy-0.10.1-py3-none-any.whl (48 kB)\n",
      "     ---------------------------------------- 48.9/48.9 kB 2.4 MB/s eta 0:00:00\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Downloading pydantic-1.10.5-cp39-cp39-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 11.5 MB/s eta 0:00:00\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.1-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.7-cp39-cp39-win_amd64.whl (30 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.5-cp39-cp39-win_amd64.whl (481 kB)\n",
      "     ------------------------------------- 481.4/481.4 kB 14.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.9-cp39-cp39-win_amd64.whl (18 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.9-cp39-cp39-win_amd64.whl (7.0 MB)\n",
      "     ---------------------------------------- 7.0/7.0 MB 16.6 MB/s eta 0:00:00\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.0.4-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.4)\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Installing collected packages: cymem, spacy-loggers, spacy-legacy, pydantic, murmurhash, langcodes, colorama, catalogue, blis, wasabi, srsly, preshed, typer, confection, thinc, pathy, spacy\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.5\n",
      "    Uninstalling colorama-0.4.5:\n",
      "      Successfully uninstalled colorama-0.4.5\n",
      "Successfully installed blis-0.7.9 catalogue-2.0.8 colorama-0.4.6 confection-0.0.4 cymem-2.0.7 langcodes-3.3.0 murmurhash-1.0.9 pathy-0.10.1 preshed-3.0.8 pydantic-1.10.5 spacy-3.5.0 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.5 thinc-8.1.7 typer-0.7.0 wasabi-1.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anaconda-project 0.11.1 requires ruamel-yaml, which is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 12.8/12.8 MB 6.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.5.0) (3.5.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.7)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (21.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (63.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.21.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.11.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (5.2.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.9.14)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\loviy\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.5.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: Great, Spacy POS Tag: ADJ, NLTK POS Tag: NN\n",
      "Word: buy, Spacy POS Tag: NOUN, NLTK POS Tag: VB\n",
      "Word: ,, Spacy POS Tag: PUNCT, NLTK POS Tag: ,\n",
      "Word: always, Spacy POS Tag: ADV, NLTK POS Tag: RB\n",
      "Word: go, Spacy POS Tag: VERB, NLTK POS Tag: VB\n",
      "Word: with, Spacy POS Tag: ADP, NLTK POS Tag: IN\n",
      "Word: white, Spacy POS Tag: PROPN, NLTK POS Tag: JJ\n",
      "Word: dark, Spacy POS Tag: ADJ, NLTK POS Tag: NN\n",
      "Word: colors, Spacy POS Tag: NOUN, NLTK POS Tag: NNS\n",
      "Word: melt, Spacy POS Tag: VERB, NLTK POS Tag: NN\n"
     ]
    }
   ],
   "source": [
    "# 3. For same text in text file\n",
    "# 3.a) Compare the tags generated spaCy and NLTK.\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(lab5_text_raw)\n",
    "\n",
    "spacy_pos_tag_map = []\n",
    "\n",
    "for token in doc:\n",
    "    spacy_pos_tag = token.pos_\n",
    "    nltk_pos_tag = pos_tag([token.text])[0][1]\n",
    "\n",
    "    spacy_pos_tag_map.append({\n",
    "        \"word\": token.text,\n",
    "        \"spacy_pos_tag\": spacy_pos_tag,\n",
    "        \"nltk_pos_tag\": nltk_pos_tag\n",
    "    })\n",
    "\n",
    "for word in spacy_pos_tag_map[:10]:\n",
    "    print(f\"Word: {word['word']}, Spacy POS Tag: {word['spacy_pos_tag']}, NLTK POS Tag: {word['nltk_pos_tag']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Give few product reviews from the file: LabE_5.txt\n",
    "\n",
    "a. Extract product descriptors of the concerned product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load English language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# process text\n",
    "text = \"This product is amazing. It's really easy to use and has great features.\"\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Here use spaCy : for getting descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This product', 'It', 'great features']\n"
     ]
    }
   ],
   "source": [
    "# extract noun phrases\n",
    "noun_phrases = [chunk.text for chunk in doc.noun_chunks]\n",
    "\n",
    "print(noun_phrases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4fc14cfe266f72e2b60b8f11f2f57377376f5ef662aa88be7ba3ee6e3e3df6cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
